{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HDS4OqhdPmaU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1m1moQLkLWh4"
      },
      "outputs": [],
      "source": [
        "X=[]\n",
        "Z=[]\n",
        "IMG_SIZE=150\n",
        "FLOWER_DAISY_DIR = r\"/content/drive/MyDrive/flowers/daisy\"\n",
        "FLOWER_SUNFLOWER_DIR=r\"/content/drive/MyDrive/flowers/sunflower\"\n",
        "FLOWER_TULIP_DIR=r\"/content/drive/MyDrive/flowers/tulip\"\n",
        "FLOWER_DANDI_DIR=r\"/content/drive/MyDrive/flowers/dandelion\"\n",
        "FLOWER_ROSE_DIR=r\"/content/drive/MyDrive/flowers/rose\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Er_rpUvNND9B"
      },
      "outputs": [],
      "source": [
        "def assign_label(img, flower_type):\n",
        "    if flower_type == 'daisy':\n",
        "        return 0\n",
        "    elif flower_type == 'sunflower':\n",
        "        return 1\n",
        "    elif flower_type == 'tulip':\n",
        "        return 2\n",
        "    elif flower_type == 'dandelion':\n",
        "        return 3\n",
        "    elif flower_type == 'rose':\n",
        "        return 4\n",
        "    else:\n",
        "        return -1  # Unknown flower type\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p39Sc5eWNjTC"
      },
      "outputs": [],
      "source": [
        "def make_train_data(flower_type, DIR):\n",
        "    for img in tqdm(os.listdir(DIR)):\n",
        "        label = assign_label(img, flower_type)\n",
        "        if label != -1:\n",
        "            path = os.path.join(DIR, img)\n",
        "            img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))  # Resize images to 150x150 pixels\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert images to RGB format\n",
        "            img = img.astype(np.float32) / 255.0  # Normalize pixel values to range [0, 1]\n",
        "            X.append(np.array(img))\n",
        "            Z.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-ak3RJtOYOr",
        "outputId": "3f562655-d7e7-4c65-97fa-61da56752c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 764/764 [00:19<00:00, 38.97it/s] \n",
            "100%|██████████| 733/733 [00:15<00:00, 46.37it/s] \n",
            "100%|██████████| 984/984 [00:28<00:00, 34.74it/s] \n",
            "100%|██████████| 1062/1062 [00:25<00:00, 42.14it/s] \n",
            "100%|██████████| 784/784 [00:17<00:00, 44.12it/s] \n"
          ]
        }
      ],
      "source": [
        "# Call make_train_data function for each flower type\n",
        "make_train_data('daisy', FLOWER_DAISY_DIR)\n",
        "make_train_data('sunflower', FLOWER_SUNFLOWER_DIR)\n",
        "make_train_data('tulip', FLOWER_TULIP_DIR)\n",
        "make_train_data('dandelion', FLOWER_DANDI_DIR)\n",
        "make_train_data('rose', FLOWER_ROSE_DIR)\n",
        "\n",
        "# Total number of records\n",
        "total_records = len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AU7VeKwet9Dz"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "Y=le.fit_transform(Z)\n",
        "Y=to_categorical(Y,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3B2aQcHuzw9",
        "outputId": "f1ed8fd7-dd69-4f9a-e22a-6a3b4e2bd93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "X_train shape: (3245, 150, 150, 3)\n",
            "Y_train shape: (3245, 5)\n",
            "\n",
            "Test set:\n",
            "X_test shape: (1082, 150, 150, 3)\n",
            "Y_test shape: (1082, 5)\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and test sets (75/25 ratio)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Print the shapes of the training and test sets\n",
        "print(\"Training set:\")\n",
        "print(\"X_train shape:\", np.array(X_train).shape)\n",
        "print(\"Y_train shape:\", np.array(Y_train).shape)\n",
        "print(\"\\nTest set:\")\n",
        "print(\"X_test shape:\", np.array(X_test).shape)\n",
        "print(\"Y_test shape:\", np.array(Y_test).shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeVpCL0VvA1C",
        "outputId": "067e0a97-2286-466d-da26-64c01906be96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-3c35342518d2>:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  X_train = torch.tensor(X_train, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
        "Y_test = torch.tensor(Y_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "x64t7Ek9FBJW"
      },
      "outputs": [],
      "source": [
        "# Reshape input tensors to (batch_size, 3, 150, 150)\n",
        "X_train = X_train.permute(0, 3, 1, 2)\n",
        "X_test = X_test.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW0u8ahGytr6",
        "outputId": "778eab48-b7a9-4657-fb9f-8f5da5163b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 153MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained ResNet model\n",
        "pretrained_resnet = models.resnet50(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UkohMKxSzDSU"
      },
      "outputs": [],
      "source": [
        "# Modify the fully connected layer for flower classification\n",
        "num_ftrs = pretrained_resnet.fc.in_features\n",
        "pretrained_resnet.fc = nn.Linear(num_ftrs, 5)  # Assuming 5 flower classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bmw7dnu8zDYy"
      },
      "outputs": [],
      "source": [
        "# Freeze convolutional layers\n",
        "for param in pretrained_resnet.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jqtZmgFVzDbd"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(pretrained_resnet.fc.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZVca__VXzDe6"
      },
      "outputs": [],
      "source": [
        "# Move model and data to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pretrained_resnet.to(device)\n",
        "X_train, X_test, Y_train, Y_test = X_train.to(device), X_test.to(device), Y_train.to(device), Y_test.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iI54wsmzLy6",
        "outputId": "967a7d3a-f497-4444-c50d-8f6238e158fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 1.6098, Train Accuracy: 3.9914\n",
            "Epoch [2/10], Train Loss: 1.6098, Train Accuracy: 3.9914\n",
            "Epoch [3/10], Train Loss: 1.6098, Train Accuracy: 3.9914\n",
            "Epoch [4/10], Train Loss: 1.6098, Train Accuracy: 3.9914\n",
            "Epoch [5/10], Train Loss: 1.6098, Train Accuracy: 3.9914\n",
            "Epoch [6/10], Train Loss: 1.6098, Train Accuracy: 3.9914\n",
            "Epoch [7/10], Train Loss: 1.6098, Train Accuracy: 3.9914\n",
            "Epoch [8/10], Train Loss: 1.6098, Train Accuracy: 3.9914\n",
            "Epoch [9/10], Train Loss: 1.6098, Train Accuracy: 3.9914\n",
            "Epoch [10/10], Train Loss: 1.6098, Train Accuracy: 3.9914\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    pretrained_resnet.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in zip(X_train, Y_train):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Add batch dimension to input tensor\n",
        "        inputs = inputs.unsqueeze(0)\n",
        "\n",
        "        # Convert input tensor to floating point type and ensure it requires gradients\n",
        "        inputs = inputs.float()\n",
        "        inputs.requires_grad = True\n",
        "\n",
        "        outputs = pretrained_resnet(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)  # Get predicted class indices\n",
        "\n",
        "        # Add batch dimension to labels tensor and convert to LongTensor\n",
        "        labels = labels.unsqueeze(0).float()\n",
        "\n",
        "        # Compute loss directly using class indices (no need to convert labels)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()  # Compare with original labels\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_accuracy = correct / total\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SII1-qrSzL1X",
        "outputId": "193a4b87-a107-49a4-9d3a-342a638fc339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.1645\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "pretrained_resnet.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in zip(X_test, Y_test):\n",
        "        inputs, labels = inputs.unsqueeze(0), labels.unsqueeze(0)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = pretrained_resnet(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(torch.argmax(labels)).sum().item()\n",
        "\n",
        "    test_accuracy = correct / total\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR TENSORFLOW"
      ],
      "metadata": {
        "id": "rOEzvan4TC3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model"
      ],
      "metadata": {
        "id": "mQAEsfeyTFG0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet50 model excluding the top layers\n",
        "base_model = tf.keras.applications.ResNet50(input_shape=(150, 150, 3),\n",
        "                                            include_top=False,\n",
        "                                            weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRImgBnzTKN5",
        "outputId": "23a5d3e0-ca94-442a-dcef-cc6ec0fb2376"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the pre-trained layers\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "psSSHp_CTNb3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new fully connected layer for flower classification\n",
        "x = base_model.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "predictions = layers.Dense(5, activation='softmax')(x)  # Assuming 5 flower classes"
      ],
      "metadata": {
        "id": "__xA2s1UTQbp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "fAnfWIE_TTKh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2vyuD03LTVoY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "H69Gj0k1TYpo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to NumPy arrays\n",
        "X_train_np = np.array(X_train)\n",
        "X_test_np = np.array(X_test)\n",
        "Y_train_np = np.array(Y_train)\n",
        "Y_test_np = np.array(Y_test)"
      ],
      "metadata": {
        "id": "cN6q9HDuTtS_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the data sizes match\n",
        "assert len(X_train_np) == len(Y_train_np), \"Training data and labels have different sizes\"\n",
        "assert len(X_test_np) == len(Y_test_np), \"Test data and labels have different sizes\""
      ],
      "metadata": {
        "id": "E5kaU2S_Tudn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train_np, Y_train_np, epochs=20, batch_size=32, validation_data=(X_test_np, Y_test_np))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUsgJw71TbNV",
        "outputId": "6cabc605-1bd1-43a3-b05f-bc0406435eab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "102/102 [==============================] - 19s 112ms/step - loss: 1.5406 - accuracy: 0.3174 - val_loss: 1.4814 - val_accuracy: 0.3577\n",
            "Epoch 2/20\n",
            "102/102 [==============================] - 7s 69ms/step - loss: 1.4831 - accuracy: 0.3683 - val_loss: 1.4391 - val_accuracy: 0.4067\n",
            "Epoch 3/20\n",
            "102/102 [==============================] - 8s 81ms/step - loss: 1.4431 - accuracy: 0.3840 - val_loss: 1.4151 - val_accuracy: 0.4316\n",
            "Epoch 4/20\n",
            "102/102 [==============================] - 8s 79ms/step - loss: 1.4139 - accuracy: 0.4086 - val_loss: 1.3678 - val_accuracy: 0.4418\n",
            "Epoch 5/20\n",
            "102/102 [==============================] - 7s 70ms/step - loss: 1.3962 - accuracy: 0.4194 - val_loss: 1.3914 - val_accuracy: 0.4603\n",
            "Epoch 6/20\n",
            "102/102 [==============================] - 7s 71ms/step - loss: 1.3620 - accuracy: 0.4579 - val_loss: 1.3359 - val_accuracy: 0.4501\n",
            "Epoch 7/20\n",
            "102/102 [==============================] - 8s 78ms/step - loss: 1.3530 - accuracy: 0.4330 - val_loss: 1.3515 - val_accuracy: 0.4205\n",
            "Epoch 8/20\n",
            "102/102 [==============================] - 8s 80ms/step - loss: 1.3370 - accuracy: 0.4579 - val_loss: 1.3409 - val_accuracy: 0.4362\n",
            "Epoch 9/20\n",
            "102/102 [==============================] - 7s 70ms/step - loss: 1.3144 - accuracy: 0.4616 - val_loss: 1.2925 - val_accuracy: 0.4797\n",
            "Epoch 10/20\n",
            "102/102 [==============================] - 7s 71ms/step - loss: 1.2945 - accuracy: 0.4832 - val_loss: 1.4370 - val_accuracy: 0.4196\n",
            "Epoch 11/20\n",
            "102/102 [==============================] - 7s 72ms/step - loss: 1.2911 - accuracy: 0.4715 - val_loss: 1.2904 - val_accuracy: 0.4445\n",
            "Epoch 12/20\n",
            "102/102 [==============================] - 7s 69ms/step - loss: 1.2644 - accuracy: 0.4884 - val_loss: 1.3341 - val_accuracy: 0.4381\n",
            "Epoch 13/20\n",
            "102/102 [==============================] - 7s 71ms/step - loss: 1.2613 - accuracy: 0.4875 - val_loss: 1.3365 - val_accuracy: 0.4501\n",
            "Epoch 14/20\n",
            "102/102 [==============================] - 7s 69ms/step - loss: 1.2473 - accuracy: 0.4968 - val_loss: 1.2447 - val_accuracy: 0.5120\n",
            "Epoch 15/20\n",
            "102/102 [==============================] - 8s 80ms/step - loss: 1.2420 - accuracy: 0.5079 - val_loss: 1.2619 - val_accuracy: 0.5009\n",
            "Epoch 16/20\n",
            "102/102 [==============================] - 8s 78ms/step - loss: 1.2047 - accuracy: 0.5140 - val_loss: 1.2141 - val_accuracy: 0.5092\n",
            "Epoch 17/20\n",
            "102/102 [==============================] - 7s 70ms/step - loss: 1.2004 - accuracy: 0.5159 - val_loss: 1.2034 - val_accuracy: 0.5388\n",
            "Epoch 18/20\n",
            "102/102 [==============================] - 8s 79ms/step - loss: 1.1931 - accuracy: 0.5313 - val_loss: 1.2808 - val_accuracy: 0.5194\n",
            "Epoch 19/20\n",
            "102/102 [==============================] - 8s 79ms/step - loss: 1.1967 - accuracy: 0.5208 - val_loss: 1.2525 - val_accuracy: 0.5129\n",
            "Epoch 20/20\n",
            "102/102 [==============================] - 7s 70ms/step - loss: 1.2069 - accuracy: 0.5079 - val_loss: 1.2383 - val_accuracy: 0.5055\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a679c738a00>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_np, Y_test_np)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlm9arDKTclR",
        "outputId": "ea636296-859e-4ef8-9291-ce0a07c6ca03"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 2s 52ms/step - loss: 1.2383 - accuracy: 0.5055\n",
            "Test Loss: 1.2382563352584839, Test Accuracy: 0.5055452585220337\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}